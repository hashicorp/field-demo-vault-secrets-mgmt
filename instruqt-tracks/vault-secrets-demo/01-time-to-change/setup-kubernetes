#!/bin/bash -l

set -e

###########
# Install Postgres client for testing
###########
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-get update
sudo apt-get install -y postgresql-client
apt install postgresql-client-common

###########
# Install Consul Client
###########
CONSUL_VERSION=1.9.7
wget https://releases.hashicorp.com/consul/${CONSUL_VERSION}/consul_${CONSUL_VERSION}_linux_amd64.zip
unzip consul_${CONSUL_VERSION}_linux_amd64.zip
mv consul /usr/local/bin/consul
chmod +x /usr/local/bin/consul
rm -f consul_${CONSUL_VERSION}_linux_amd64.zip

###########
# Install Vault Client
###########
VAULT_VERSION=1.7.3
wget https://releases.hashicorp.com/vault/${VAULT_VERSION}/vault_${VAULT_VERSION}_linux_amd64.zip
unzip vault_${VAULT_VERSION}_linux_amd64.zip
mv vault /usr/local/bin/vault
chmod +x /usr/local/bin/vault
rm -f vault_${VAULT_VERSION}_linux_amd64.zip

###########
# Configure Vault Helm Chart values
###########
cat <<-EOF >/root/vault-values.yaml
injector:
  agentImage:
    repository: "hashicorp/vault"
    tag: "1.7.3"
server:
  image:
    repository: "hashicorp/vault"
    tag: "1.7.3"
    pullPolicy: IfNotPresent
  dev:
    enabled: true
  standalone:
    enabled: true
    config: |
      ui = true
      listener "tcp" {
        tls_disable = 1
        address = "[::]:8200"
        cluster_address = "[::]:8201"
      }
      storage "file" {
        path = "/vault/data"
      }
  annotations:
    consul.hashicorp.com/connect-inject: "true"
ui:
  enabled: true
  serviceType: NodePort
  externalPort: 8200
  serviceNodePort: 30082
EOF

###########
# Install Vault with the Helm Chart
###########
openssl genrsa -out injector-ca.key 2048
openssl req \
   -x509 \
   -new \
   -nodes \
   -key injector-ca.key \
   -sha256 \
   -days 1825 \
   -out injector-ca.crt \
   -subj "/C=US/ST=CA/L=San Francisco/O=HashiCorp/CN=vault-agent-injector-svc"
openssl genrsa -out tls.key 2048
openssl req \
   -new \
   -key tls.key \
   -out tls.csr \
   -subj "/C=US/ST=CA/L=San Francisco/O=HashiCorp/CN=vault-agent-injector-svc"
cat <<EOF >csr.conf
authorityKeyIdentifier=keyid,issuer
basicConstraints=CA:FALSE
keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
subjectAltName = @alt_names

[alt_names]
DNS.1 = vault-agent-injector-svc
DNS.2 = vault-agent-injector-svc.vault
DNS.3 = vault-agent-injector-svc.vault.svc
DNS.4 = vault-agent-injector-svc.vault.svc.cluster.local
EOF
openssl x509 \
  -req \
  -in tls.csr \
  -CA injector-ca.crt \
  -CAkey injector-ca.key \
  -CAcreateserial \
  -out tls.crt \
  -days 1825 \
  -sha256 \
  -extfile csr.conf
kubectl create secret generic injector-tls \
    --from-file tls.crt \
    --from-file tls.key
export CA_BUNDLE=$(cat injector-ca.crt | base64)
helm repo add hashicorp https://helm.releases.hashicorp.com
helm install vault hashicorp/vault \
  --wait --values /root/vault-values.yaml --version 0.11.0 \
  --set="injector.certs.secretName=injector-tls" \
  --set="injector.certs.caBundle=${CA_BUNDLE?}"

###########
# Configure Consul Helm Chart values
###########
cat <<-EOF >/root/consul-values.yaml
global:
  datacenter: dc1
  image: "consul:1.9.7"
  imageK8S: "hashicorp/consul-k8s:0.25.0"
server:
  replicas: 1
  bootstrapExpect: 1
client:
  enabled: true
  grpc: true
ui:
  enabled: true
connectInject:
  enabled: true
syncCatalog:
  enabled: true
  toConsul: true
  toK8S: false
  default: true
EOF

###########
# Install Consul with the Helm Chart
###########
helm install --wait -f /root/consul-values.yaml hashicorp hashicorp/consul --version 0.31.1

###########
# Setup the UI for Consul
###########
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: Service
metadata:
  name: hashicups-consul-ui-nodeport
  labels:
    app: consul
spec:
  type: NodePort
  selector:
    app: consul
    component: server
  ports:
  - name: http
    protocol: TCP
    port: 8500
    targetPort: 8500
    nodePort: 30085
EOF

###########
# Create a directory for the k8s .yaml files
###########
mkdir /root/k8s/

###########
# Set up Postgres Products DB Kubernetes Deployment
###########
cat <<-EOF >/root/k8s/products-db.yml
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  type: ClusterIP
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    app: postgres
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      service: postgres
      app: postgres
  template:
    metadata:
      labels:
        service: postgres
        app: postgres
      annotations:
        consul.hashicorp.com/connect-inject: "true"
    spec:
      containers:
        - name: postgres
          image: hashicorpdemoapp/product-api-db:v0.0.11
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_DB
              value: products
            - name: POSTGRES_USER
              value: postgres
            - name: POSTGRES_PASSWORD
              value: password
          volumeMounts:
            - mountPath: "/var/lib/postgresql/data"
              name: "pgdata"
      volumes:
        - name: pgdata
          emptyDir: {}
EOF

kubectl apply -f /root/k8s/products-db.yml

###########
# Set up Products API Kubernetes Deployment
###########
cat <<-EOF >/root/k8s/products-api.yml
---
# Service to expose web frontend
apiVersion: v1
kind: Service
metadata:
  name: products-api-service
  labels:
    app: products-api
spec:
  selector:
    app: products-api
  ports:
    - name: http
      protocol: TCP
      port: 9090
      targetPort: 9090
---
# Service account to allow pod access to Vault via K8s auth
apiVersion: v1
kind: ServiceAccount
metadata:
  name: products-api
automountServiceAccountToken: true
---
# Web frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: products-api-deployment
  labels:
    app: products-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: products-api
  template:
    metadata:
      labels:
        app: products-api
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "postgres:5432"
        vault.hashicorp.com/log-level: "debug"
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/agent-inject-secret-db-creds: "kv/db/postgres/product-db-creds"
        vault.hashicorp.com/agent-inject-template-db-creds: |
          {
          {{ with secret "kv/db/postgres/product-db-creds" -}}
            "db_connection": "host=localhost port=5432 user={{ .Data.username }} password={{ .Data.password }} dbname=products sslmode=disable",
            "bind_address": ":9090",
            "metrics_address": ":9103"
          {{- end }}
          }
        vault.hashicorp.com/role: "products-api"
    spec:
      serviceAccountName: products-api
      containers:
        - name: products-api
          image: hashicorpdemoapp/product-api:v0.0.11
          ports:
            - containerPort: 9090
            - containerPort: 9102
          env:
            - name: "CONFIG_FILE"
              value: "/vault/secrets/db-creds"
          livenessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 15
            timeoutSeconds: 1
            periodSeconds: 10
            failureThreshold: 30
---
# https://www.vaultproject.io/docs/auth/kubernetes/#configuring-kubernetes
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: role-tokenreview-binding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
  - kind: ServiceAccount
    name: products-api
    namespace: default
EOF

kubectl apply -f /root/k8s/products-api.yml

###########
# Set up Public API Kubernetes Deployment
###########
cat <<-EOF >/root/k8s/public-api.yml
---
apiVersion: v1
kind: Service
metadata:
  name: public-api-svc
  labels:
    app: public-api
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: public-api
---
apiVersion: v1
kind: Service
metadata:
  name: public-api-ui
  labels:
    app: public-api
spec:
  type: NodePort
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
  selector:
    app: public-api
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: public-api
spec:
  replicas: 1
  selector:
    matchLabels:
      service: public-api
      app: public-api
  template:
    metadata:
      labels:
        service: public-api
        app: public-api
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "products-api:9090"
    spec:
      containers:
        - name: public-api
          image: hashicorpdemoapp/public-api:v0.0.1
          ports:
            - containerPort: 8080
          env:
            - name: BIND_ADDRESS
              value: ":8080"
            - name: PRODUCTS_API_URI
              value: "http://localhost:9090"
EOF

kubectl apply -f /root/k8s/public-api.yml

###########
# Set up Frontend Kubernetes Deployment
###########

cat <<-EOF >/root/k8s/frontend.yml
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-ui
  labels:
    app: frontend
spec:
  type: NodePort
  selector:
    app: frontend
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30090
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configmap
data:
  config: |
    # /etc/nginx/conf.d/default.conf
    server {
        listen       80;
        server_name  localhost;
        #charset koi8-r;
        #access_log  /var/log/nginx/host.access.log  main;
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }
        # Proxy pass the api location to save CORS
        # Use location exposed by Consul connect
        location /api {
            proxy_pass http://127.0.0.1:8080;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      service: frontend
      app: frontend
  template:
    metadata:
      labels:
        service: frontend
        app: frontend
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "public-api:8080"
    spec:
      volumes:
      - name: config
        configMap:
          name: nginx-configmap
          items:
          - key: config
            path: default.conf
      containers:
        - name: frontend
          image: hashicorpdemoapp/frontend:v0.0.3
          ports:
            - containerPort: 80
          volumeMounts:
            - name: config
              mountPath: /etc/nginx/conf.d
              readOnly: true
EOF

kubectl apply -f /root/k8s/frontend.yml

###########
# Set Vault env vars for client usage
###########
export VAULT_IP=$(kubectl get svc vault -o=json | jq -r .spec.clusterIP)
export VAULT_ADDR="http://$VAULT_IP:8200"
export VAULT_TOKEN="root"
echo "export VAULT_ADDR=$VAULT_ADDR" >>/root/.bashrc
echo "export VAULT_TOKEN=$VAULT_TOKEN" >>/root/.bashrc

###########
# Wait for Vault to start
###########
sleep 10

###########
# Set up the Kubernetes auth method with k3s
###########
vault auth enable kubernetes

export SA_NAME="products-api"
export SA_NAMESPACE=$(kubectl get sa $SA_NAME -o jsonpath="{.metadata.namespace}")
export VAULT_SECRET_NAME=$(kubectl get sa $SA_NAME -o jsonpath="{.secrets[*]['name']}")
export SA_JWT_TOKEN=$(
  kubectl get secret $VAULT_SECRET_NAME -o jsonpath="{.data.token}" | base64 --decode
  echo
)
export SA_CA_CRT="$(
  kubectl get secret $VAULT_SECRET_NAME -o jsonpath="{.data['ca\.crt']}" | base64 --decode
  echo
)"
export K8S_HOST=$(kubectl get svc kubernetes -o=json | jq -r .spec.clusterIP)

# Tell Vault how to communicate with the Kubernetes cluster
vault write auth/kubernetes/config \
  token_reviewer_jwt="$SA_JWT_TOKEN" \
  kubernetes_host="https://$K8S_HOST:443" \
  kubernetes_ca_cert="$SA_CA_CRT"

# Create a role to map Kubernetes Service Account to Vault policies and default token TTL
vault write auth/kubernetes/role/$SA_NAME \
  bound_service_account_names=$SA_NAME \
  bound_service_account_namespaces="$SA_NAMESPACE" \
  policies=products-api \
  ttl=24h

###########
# Seed Secrets
###########
# Create the KV secrets engine for static secrets
vault secrets enable -path="kv" kv

# Place an example secret in a "shared" mount to demo a bad secret management practice
mkdir -p /share/
echo "username=postgres
password=password" >/share/postgres-product-creds.txt

# Don't change the password here, the user will update it in a challenge.
vault kv put kv/db/postgres/product-db-creds username=postgres password=replacemeplz

###########
# User Policies
###########

mkdir -p /root/policies/

tee /root/policies/dba-operator-policy.hcl <<EOF
path "kv/db/*" {
  capabilities = ["list", "read", "create", "update"]
}
EOF

tee /root/policies/security-policy.hcl <<EOF
path "kv/db/*" {
  capabilities = ["read"]
}
path "kv/api/*" {
  capabilities = ["read"]
}
EOF

###########
# Service Policies
###########
tee /root/policies/products-api-policy.hcl <<EOF
path "kv/db/postgres/product-db-creds" {
  capabilities = ["read"]
}
EOF

vault policy write products-api /root/policies/products-api-policy.hcl

exit 0
