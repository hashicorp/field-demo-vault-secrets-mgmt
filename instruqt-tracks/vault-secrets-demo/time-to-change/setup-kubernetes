#!/bin/sh

###########
# Install Postgres client for testing
###########
sudo apt-get update
sudo apt-get install -y postgresql-client
apt install postgresql-client-common


###########
# Install Consul Client
###########
wget https://releases.hashicorp.com/consul/1.6.1/consul_1.6.1_linux_amd64.zip
unzip consul_1.6.1_linux_amd64.zip
mv consul /usr/local/bin/consul
chmod +x /usr/local/bin/consul
rm -f consul_1.6.1_linux_amd64.zip


###########
# Install Vault Client
###########
wget https://releases.hashicorp.com/vault/1.3.1/vault_1.3.1_linux_amd64.zip
unzip vault_1.3.1_linux_amd64.zip
mv vault /usr/local/bin/vault
chmod +x /usr/local/bin/vault
rm -f vault_1.3.1_linux_amd64.zip


###########
# Wait for k3s to startup
###########
sleep 200


###########
# Grab the Vault Helm Chart
###########
git clone --branch v0.3.3 https://github.com/hashicorp/vault-helm.git


###########
# Configure Vault Helm Chart values
###########

cat <<-EOF > /root/vault-values.yaml
server:
  dev:
    enabled: true
  standalone:
    enabled: true
    config: |
      ui = true
      listener "tcp" {
        tls_disable = 1
        address = "[::]:8200"
        cluster_address = "[::]:8201"
      }
      storage "file" {
        path = "/vault/data"
      }
  annotations:
    consul.hashicorp.com/connect-inject: "true"
ui:
  enabled: true
  serviceType: NodePort
  externalPort: 8200
  serviceNodePort: 30082
EOF


###########
# Install Vault with Helm
###########
helm install --wait --name hashicups-vault -f /root/vault-values.yaml vault-helm/


###########
# Grab the Consul Helm Chart
###########
git clone --branch v0.16.0 https://github.com/hashicorp/consul-helm.git


###########
# Configure Consul Helm Chart values
###########
cat <<-EOF > /root/consul-values.yaml
global:
  datacenter: dc1
  image: "consul:1.6.2"
  imageK8S: "hashicorp/consul-k8s:0.11.0"
server:
  replicas: 1
  bootstrapExpect: 1
client:
  enabled: true
  grpc: true
ui:
  enabled: true
connectInject:
  enabled: true
syncCatalog:
  enabled: true
  toConsul: true
  toK8S: false
  default: true
EOF


###########
# Install Consul with Helm
###########
helm install --wait --name hashicups -f /root/consul-values.yaml consul-helm/


###########
# Setup the UI for Consul
###########
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: Service
metadata:
  name: hashicups-consul-ui-nodeport
  labels:
    app: consul
spec:
  type: NodePort
  selector:
    app: consul
    component: server
  ports:
  - name: http
    protocol: TCP
    port: 8500
    targetPort: 8500
    nodePort: 30085
EOF

###########
# Create a directory for the k8s .yaml files
###########
mkdir k8s/

###########
# Set up Postgres Products DB Kubernetes Deployment
###########
cat <<-EOF > /root/k8s/products-db.yml
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  type: ClusterIP
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    app: postgres
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      service: postgres
      app: postgres
  template:
    metadata:
      labels:
        service: postgres
        app: postgres
      annotations:
        consul.hashicorp.com/connect-inject: "true"
    spec:
      containers:
        - name: postgres
          image: hashicorpdemoapp/product-api-db:v0.0.11
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_DB
              value: products
            - name: POSTGRES_USER
              value: postgres
            - name: POSTGRES_PASSWORD
              value: password
          volumeMounts:
            - mountPath: "/var/lib/postgresql/data"
              name: "pgdata"
      volumes:
        - name: pgdata
          emptyDir: {}
EOF

kubectl apply -f /root/k8s/products-db.yml


###########
# Set up Products API Kubernetes Deployment
###########
cat <<-EOF > /root/k8s/products-api.yml
---
# Service to expose web frontend
apiVersion: v1
kind: Service
metadata:
  name: products-api-service
  labels:
    app: products-api
spec:
  selector:
    app: products-api
  ports:
    - name: http
      protocol: TCP
      port: 9090
      targetPort: 9090
---
# Service account to allow pod access to Vault via K8s auth
apiVersion: v1
kind: ServiceAccount
metadata:
  name: products-api
automountServiceAccountToken: true
---
# Web frontend
apiVersion: apps/v1
kind: Deployment
metadata:
  name: products-api-deployment
  labels:
    app: products-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: products-api
  template:
    metadata:
      labels:
        app: products-api
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "postgres:5432"
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/agent-inject-secret-db-creds: "kv/db/postgres/product-db-creds"
        vault.hashicorp.com/agent-inject-template-db-creds: |
          {
          {{ with secret "kv/db/postgres/product-db-creds" -}}
            "db_connection": "host=localhost port=5432 user={{ .Data.username }} password={{ .Data.password }} dbname=products sslmode=disable",
            "bind_address": ":9090",
            "metrics_address": ":9103"
          {{- end }}
          }
        vault.hashicorp.com/role: "products-api"
    spec:
      serviceAccountName: products-api
      containers:
        - name: products-api
          image: hashicorpdemoapp/product-api:v0.0.11
          ports:
            - containerPort: 9090
            - containerPort: 9102
          env:
            - name: "CONFIG_FILE"
              value: "/vault/secrets/db-creds"
          livenessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 15
            timeoutSeconds: 1
            periodSeconds: 10
            failureThreshold: 30
---
# https://www.vaultproject.io/docs/auth/kubernetes/#configuring-kubernetes
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: role-tokenreview-binding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
  - kind: ServiceAccount
    name: products-api
    namespace: default
EOF

kubectl apply -f /root/k8s/products-api.yml


###########
# Set up Public API Kubernetes Deployment
###########
cat <<-EOF > /root/k8s/public-api.yml
---
apiVersion: v1
kind: Service
metadata:
  name: public-api-svc
  labels:
    app: public-api
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: public-api
---
apiVersion: v1
kind: Service
metadata:
  name: public-api-ui
  labels:
    app: public-api
spec:
  type: NodePort
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
  selector:
    app: public-api
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: public-api
spec:
  replicas: 1
  selector:
    matchLabels:
      service: public-api
      app: public-api
  template:
    metadata:
      labels:
        service: public-api
        app: public-api
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "products-api:9090"
    spec:
      containers:
        - name: public-api
          image: hashicorpdemoapp/public-api:v0.0.1
          ports:
            - containerPort: 8080
          env:
            - name: BIND_ADDRESS
              value: ":8080"
            - name: PRODUCTS_API_URI
              value: "http://localhost:9090"
EOF

kubectl apply -f /root/k8s/public-api.yml


###########
# Set up Frontend Kubernetes Deployment
###########

cat <<-EOF > /root/k8s/frontend.yml
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-ui
  labels:
    app: frontend
spec:
  type: NodePort
  selector:
    app: frontend
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30090
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configmap
data:
  config: |
    # /etc/nginx/conf.d/default.conf
    server {
        listen       80;
        server_name  localhost;
        #charset koi8-r;
        #access_log  /var/log/nginx/host.access.log  main;
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }
        # Proxy pass the api location to save CORS
        # Use location exposed by Consul connect
        location /api {
            proxy_pass http://127.0.0.1:8080;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      service: frontend
      app: frontend
  template:
    metadata:
      labels:
        service: frontend
        app: frontend
      annotations:
        prometheus.io/scrape: "true"
        consul.hashicorp.com/connect-inject: "true"
        consul.hashicorp.com/connect-service-upstreams: "public-api:8080"
    spec:
      volumes:
      - name: config
        configMap:
          name: nginx-configmap
          items:
          - key: config
            path: default.conf
      containers:
        - name: frontend
          image: hashicorpdemoapp/frontend:v0.0.3
          ports:
            - containerPort: 80
          volumeMounts:
            - name: config
              mountPath: /etc/nginx/conf.d
              readOnly: true
EOF

kubectl apply -f /root/k8s/frontend.yml



###########
# Set Vault env vars for client usage
###########
export VAULT_IP=$(kubectl get svc hashicups-vault -o=json | jq -r .spec.clusterIP)
export VAULT_ADDR="http://$VAULT_IP:8200"
export VAULT_TOKEN="root"
echo "export VAULT_ADDR=$VAULT_ADDR" >> /root/.bashrc
echo "export VAULT_TOKEN=$VAULT_TOKEN" >> /root/.bashrc

###########
# Wait for Vault to start
###########
sleep 10


###########
# Set up the Kubernetes auth method with k3s
###########
vault auth enable kubernetes

export SA_NAME="products-api"
export SA_NAMESPACE=$(kubectl get sa $SA_NAME -o jsonpath="{.metadata.namespace}")
export VAULT_SECRET_NAME=$(kubectl get sa $SA_NAME -o jsonpath="{.secrets[*]['name']}")
export SA_JWT_TOKEN=$(kubectl get secret $VAULT_SECRET_NAME -o jsonpath="{.data.token}" | base64 --decode; echo)
export SA_CA_CRT="$(kubectl get secret $VAULT_SECRET_NAME -o jsonpath="{.data['ca\.crt']}" | base64 --decode; echo)"
export K8S_HOST=$(kubectl get svc kubernetes -o=json | jq -r .spec.clusterIP)

# Tell Vault how to communicate with the Kubernetes cluster
vault write auth/kubernetes/config \
  token_reviewer_jwt="$SA_JWT_TOKEN" \
  kubernetes_host="https://$K8S_HOST:443" \
  kubernetes_ca_cert="$SA_CA_CRT"

# Create a role to map Kubernetes Service Account to Vault policies and default token TTL
vault write auth/kubernetes/role/$SA_NAME \
  bound_service_account_names=$SA_NAME \
  bound_service_account_namespaces="$SA_NAMESPACE" \
  policies=products-api \
  ttl=24h

###########
# Seed Secrets
###########
vault secrets enable kv

# Create the KV secrets engine for static secrets
vault secrets enable -path="kv" kv

# Place an example secret in a "shared" mount to demo a bad secret management practice
mkdir -p /share/
echo "username=postgres
password=password" > /share/postgres-product-creds.txt

# Don't change the password here, the user will update it in a challenge.
vault kv put kv/db/postgres/product-db-creds username=postgres password=replacemeplz


###########
# User Policies
###########

mkdir -p /root/policies/

tee /root/policies/dba-operator-policy.hcl <<EOF
path "kv/db/*" {
  capabilities = ["list", "read", "create", "update"]
}
EOF

tee /root/policies/operator-policy.hcl <<EOF
path "kv/api/*" {
  capabilities = ["list", "read", "create", "update"]
}
EOF

tee /root/policies/security-policy.hcl <<EOF
path "kv/db/*" {
  capabilities = ["read"]
}
path "kv/api/*" {
  capabilities = ["read"]
}
EOF

###########
# Service Policies
###########
tee /root/policies/products-api-policy.hcl <<EOF
path "kv/db/postgres/product-db-creds" {
  capabilities = ["read"]
}
EOF

vault policy write products-api /root/policies/products-api-policy.hcl

exit 0